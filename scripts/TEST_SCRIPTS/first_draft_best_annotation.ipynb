{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD4juBrdQzyqlybIZtoNS5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-joshid/Transporter_proj/blob/main/FIXED_Best_annotationScript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilJenm2NYzRH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import argparse\n",
        "#argparse makes it easy to write user friendly command-line interfaces\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Want to parse files by drawing out most important cols. This script is focused on finding the best annotations so need to pull out the column relating to that as well as identifiers.\n",
        "\n",
        "from the HMMER doc (pg 33/227):\n",
        "E-VAL: \"the most important number is the E-value... it is the expected number of false positives (non-homologus sequences) that scored this well or better... [it] is a measure of satitical significance. the lower the E-value, the more dignificant the hit\" (doc typically considers sequences w/ E-values< 10^-3 to be significant)\n",
        "\n",
        "Score: 2nd num; what EVal is based off of. it's the log-odd score for complete sequence. doesnt depend on size of sequence DB, only on profile & target sequence (E val kinda does bc larger DBs means more false pos)\n",
        "\n",
        "bias: correction term for biased sequence comp; can be over or under aggressive, leading to missed homologus sequences or allowing non-homolog through\n",
        "\n",
        "next 3 nums are again E-val, score & bias, but these are for only for single-best scorign domain in sequenc--> idea is that we might be able to detect that a sequence is apart of a multi-domain familiy b/c it contains multiple weakly-scoriong domains. On the other hand, if the target sequence is bad (meaning, it contains a set of identical internal repeats) and  one of its repeats gives a weak hit to query profile, all repeats will sum and make sequence score look significant even if that is not the case\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8xWQrso5PVjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#handle_arguments is for taking user input for where to output file\n",
        "def handle_arguments():\n",
        "  #helps user see what they need to input\n",
        "  description = '''This script parses the tcDoms domtblout file,\n",
        "        selects the top scoring annotation for each protein listed in the\n",
        "        file, and then outputs a csv of the parsed and down-selected data.\n",
        "\n",
        "        Example usage: ./best_tcDoms.py -f domtblout.tab annotations.csv\n",
        "        '''\n",
        "  #outputs decription\n",
        "  parser = argparse.ArgumentParser(description = description)\n",
        "  #add input and output requirements; help gives user more info abt what to put\n",
        "  #input is filepath\n",
        "  #output is annotates proteinsin a csv\n",
        "  parser.add_Argument('input' , type=str, help = 'Input domtblout file' )\n",
        "  parser.add_Argument('output', type = str, help = 'Output file')\n",
        "  return parser\n",
        "\n",
        "def main():\n",
        "  #gets parser obj from handle_arguments\n",
        "  parser = handle_arguments()\n",
        "  #parses arguments into\n",
        "  args = parser.parse_args()\n",
        "  #make sure output path is valid\n",
        "  output_path = args.output\n",
        "  #checks weather given path is an existing file or not\n",
        "  if os.path.isfile(output_path):\n",
        "     raise FileExistsError('A file by the name of {} already exists.'.format(output_path))\n",
        "\n",
        "  #parse tcDoms Domtblout file\n",
        "  #outputs get placed into a dataframe\n",
        "  print(\"Parsing Domblout file\", flush = True)\n",
        "  df =pd.read_csv(\n",
        "      args.input,\n",
        "      engine = 'python',\n",
        "      sep ='\\s+',\n",
        "      skiprows = [0,1,2],\n",
        "      skipfooter = 10,\n",
        "      usecols = [0,3,6,7],\n",
        "      names = ['Target_name', 'query_name', 'E-value', 'Score']\n",
        "  )\n",
        "  #taking the best result for each query\n",
        "  print(\"Selecting the best annotation for each protein\", flush = True)\n",
        "  #new dataframe for best annoatation\n",
        "  #we take the original df and group by the query name\n",
        "  #(same query_name correlates to the same protein)\n",
        "  #we then select the index that has the max score within this group\n",
        "  #this is then assgined to best_annot_df\n",
        "  #ultimately, this profuced a Df of unique proteins what had the highest\n",
        "  #scores within groups of the same protein\n",
        "  df['score'] = df['score'].astype(float)\n",
        "  best_annot_df = df.iloc[df.groupby(['query_name']).score.idxmax()]\n",
        "  #reset index makes the indexes so that they are sequential\n",
        "  #instead of keeping the old dfs orfinal index (out-of-order now in new df)\n",
        "  #drop = true ensures a new column is not made for the old index\n",
        "  #inplace = True, this modifies the current df instead of creating a new one\n",
        "  best_annot_df.reset_index(drop = True, inplace = True)\n",
        "\n",
        "  #save results to csv\n",
        "  best_annot_df.to_csv(args.output, index = False)\n",
        "  print('Finished')\n",
        "  if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UReVe3LLcCfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELzInqJJsLky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}